{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/logpx/miniconda3/envs/rbf/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-20 10:37:10.923974: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-20 10:37:10.944099: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-20 10:37:10.944128: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-20 10:37:10.944894: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-20 10:37:10.949125: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-20 10:37:11.495099: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/logpx/miniconda3/envs/rbf/lib/python311.zip', '/home/logpx/miniconda3/envs/rbf/lib/python3.11', '/home/logpx/miniconda3/envs/rbf/lib/python3.11/lib-dynload', '', '/home/logpx/.local/lib/python3.11/site-packages', '/home/logpx/miniconda3/envs/rbf/lib/python3.11/site-packages', '/home/logpx/scpark/dpm-solver-v32/codebases/stable-diffusion/src/taming-transformers', '/home/logpx/scpark/dpm-solver-v32/codebases/stable-diffusion/src/clip', '/home/logpx/miniconda3/envs/rbf/lib/python3.11/site-packages/setuptools/_vendor', '/tmp/tmp133_hmkb']\n"
     ]
    }
   ],
   "source": [
    "from txt2img_latent import get_parser, load_model_from_config, chunk\n",
    "\n",
    "parser = get_parser()\n",
    "\n",
    "# 2) args_list 정의 (원하는 인자들을 문자열 리스트로)\n",
    "args_list = [\n",
    "    \"--config\", \"configs/stable-diffusion/v1-inference.yaml\",\n",
    "    \"--ckpt\", \"models/ldm/stable-diffusion-v1/sd-v1-4.ckpt\",\n",
    "    \"--H\", \"512\",\n",
    "    \"--W\", \"512\",\n",
    "    \"--C\", \"4\",\n",
    "    \"--f\", \"8\",\n",
    "]\n",
    "\n",
    "# 3) parse_args() 실행\n",
    "opt = parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from models/ldm/stable-diffusion-v1/sd-v1-4.ckpt\n",
      "Global Step: 470000\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = OmegaConf.load(f\"{opt.config}\")\n",
    "model = load_model_from_config(config, f\"{opt.ckpt}\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from ldm.models.diffusion.rbf import RBFSampler\n",
    "from ldm.models.diffusion.uni_pc import UniPCSampler\n",
    "\n",
    "#sampler = UniPCSampler(model)\n",
    "sampler = RBFSampler(model)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\toutputs  scale1.5  scale7.5\n"
     ]
    }
   ],
   "source": [
    "N = 128\n",
    "M = 6\n",
    "SCALE = 1.5\n",
    "\n",
    "!mkdir -p /data/ldm/scale{SCALE}\n",
    "!ls /data/ldm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 torch.Size([128, 4, 64, 64]) torch.Size([128, 4, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pt_dir = f'/data/archive/sd-v1-4/dpm_solver++_steps200_scale{SCALE}'\n",
    "pt_files = [os.path.join(pt_dir, f) for f in os.listdir(pt_dir) if '.pt' in f]\n",
    "prompts_list = []\n",
    "x_T_list = []\n",
    "x_0_list = []\n",
    "for i in range(26):\n",
    "    data = torch.load(pt_files[i])\n",
    "    prompts_list.append(data['text'])\n",
    "    x_T_list.append(data['latent'])\n",
    "    x_0_list.append(data['image'])\n",
    "\n",
    "prompts_list = np.ravel(prompts_list)[:N]\n",
    "x_T_list = torch.cat(x_T_list, dim=0)[:N]\n",
    "x_0_list = torch.cat(x_0_list, dim=0)[:N]\n",
    "print(len(prompts_list), x_T_list.shape, x_0_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ldm/scale1.5/NFE=5,p=2,number=0.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=1.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=2.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=3.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=4.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=5.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=6.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=7.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=8.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=9.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=10.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=11.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=12.npz  saved!\n",
      "/data/ldm/scale1.5/NFE=5,p=2,number=13.npz  saved!\n"
     ]
    }
   ],
   "source": [
    "from torch import autocast\n",
    "from contextlib import nullcontext\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for ORDER in [2, 3]:\n",
    "    for NFE in [5, 6, 8, 10, 12, 15, 20]:\n",
    "        for number in range(20):\n",
    "            index = np.random.randint(0, N, size=(M,))\n",
    "            prompts = list(prompts_list[index])\n",
    "            x_T = x_T_list[index].to(device)\n",
    "            x_0 = x_0_list[index].to(device)\n",
    "            precision_scope = autocast if opt.precision == \"autocast\" else nullcontext\n",
    "            with torch.no_grad():\n",
    "                with precision_scope(\"cuda\"):\n",
    "                    with model.ema_scope():\n",
    "                        uc = None\n",
    "                        if opt.scale != 1.0:\n",
    "                            uc = model.get_learned_conditioning(len(prompts) * [\"\"])\n",
    "                        c = model.get_learned_conditioning(prompts)\n",
    "                        samples, _ = sampler.target_matching(\n",
    "                            S=NFE,\n",
    "                            shape=(4, 64, 64),\n",
    "                            conditioning=c,\n",
    "                            batch_size=len(prompts),\n",
    "                            verbose=False,\n",
    "                            unconditional_guidance_scale=SCALE,\n",
    "                            unconditional_conditioning=uc,\n",
    "                            eta=0,\n",
    "                            x_T=x_T,\n",
    "                            x_0=x_0,\n",
    "                            order=ORDER,\n",
    "                            number=number,\n",
    "                            scale_dir=f'/data/ldm/scale{SCALE}'\n",
    "                        )\n",
    "\n",
    "        plt.figure(figsize=[8, 5])\n",
    "        optimal_log_scales_list = []\n",
    "        for number in range(20):\n",
    "            np_data = np.load(f'/data/ldm/scale{SCALE}/NFE={NFE},p={ORDER},number={number}.npz')\n",
    "            optimal_log_scales_list.append(np_data['optimal_log_scales'])\n",
    "            plt.plot(np_data['optimal_log_scales'].T, color='black', alpha=0.1)\n",
    "\n",
    "        optimal_log_scales_list = np.stack(optimal_log_scales_list, axis=0)\n",
    "        optimal_log_scales = np.mean(optimal_log_scales_list, axis=0)\n",
    "        np.savez(f'/data/ldm/scale{SCALE}/NFE={NFE},p={ORDER}.npz', optimal_log_scales=optimal_log_scales)\n",
    "        np_data = np.load(f'/data/ldm/scale{SCALE}/NFE={NFE},p={ORDER}.npz')\n",
    "        plt.plot(np_data['optimal_log_scales'].T, color='blue', alpha=1)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
