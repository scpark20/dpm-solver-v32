{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/archive/sd-v1-4/dpm_solver++_steps5_scale1.5 0.2605 N=10000\n",
      "/data/archive/sd-v1-4/uni_pc_bh2_steps5_scale1.5 0.2363 N=10000\n",
      "/data/archive/sd-v1-4/dpm_solver_v3_steps5_scale1.5 0.2019 N=10000\n",
      "/data/archive/sd-v1-4/rbf_order2_steps5_scale1.5 0.2240 N=10000\n",
      "/data/archive/sd-v1-4/rbf_order3_steps5_scale1.5 0.2202 N=10000\n",
      "\n",
      "/data/archive/sd-v1-4/dpm_solver++_steps6_scale1.5 0.2252 N=10000\n",
      "/data/archive/sd-v1-4/uni_pc_bh2_steps6_scale1.5 0.2030 N=10000\n",
      "/data/archive/sd-v1-4/dpm_solver_v3_steps6_scale1.5 0.1756 N=10000\n",
      "/data/archive/sd-v1-4/rbf_order2_steps6_scale1.5 0.1926 N=10000\n",
      "/data/archive/sd-v1-4/rbf_order3_steps6_scale1.5 0.1905 N=10000\n",
      "\n",
      "/data/archive/sd-v1-4/dpm_solver++_steps8_scale1.5 0.1801 N=10000\n",
      "/data/archive/sd-v1-4/uni_pc_bh2_steps8_scale1.5 0.1589 N=10000\n",
      "/data/archive/sd-v1-4/dpm_solver_v3_steps8_scale1.5 0.1344 N=10000\n",
      "/data/archive/sd-v1-4/rbf_order2_steps8_scale1.5 0.1506 N=10000\n",
      "/data/archive/sd-v1-4/rbf_order3_steps8_scale1.5 0.1500 N=10000\n",
      "\n",
      "/data/archive/sd-v1-4/dpm_solver++_steps10_scale1.5 0.1505 N=10000\n",
      "/data/archive/sd-v1-4/uni_pc_bh2_steps10_scale1.5 0.1278 N=10000\n",
      "/data/archive/sd-v1-4/dpm_solver_v3_steps10_scale1.5 0.1040 N=10000\n",
      "/data/archive/sd-v1-4/rbf_order2_steps10_scale1.5 0.1203 N=10000\n",
      "/data/archive/sd-v1-4/rbf_order3_steps10_scale1.5 0.1174 N=10000\n",
      "\n",
      "/data/archive/sd-v1-4/dpm_solver++_steps12_scale1.5 0.1285 N=10000\n",
      "/data/archive/sd-v1-4/uni_pc_bh2_steps12_scale1.5 0.1045 N=10000\n",
      "/data/archive/sd-v1-4/dpm_solver_v3_steps12_scale1.5 0.0806 N=10000\n",
      "/data/archive/sd-v1-4/rbf_order2_steps12_scale1.5 0.0976 N=10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     25\u001b[39m ref_data = torch.load(ref_file)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m comp_data = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m mses = torch.sqrt(torch.mean((ref_data[\u001b[33m'\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m'\u001b[39m] - comp_data[\u001b[33m'\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m'\u001b[39m]) ** \u001b[32m2\u001b[39m, dim=[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]))\n\u001b[32m     28\u001b[39m mse_list.append(mses)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rbf/lib/python3.11/site-packages/torch/serialization.py:1426\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m-> \u001b[39m\u001b[32m1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_zipfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n\u001b[32m   1431\u001b[39m         overall_storage = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rbf/lib/python3.11/site-packages/torch/serialization.py:433\u001b[39m, in \u001b[36m_is_zipfile\u001b[39m\u001b[34m(f)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;66;03m# Read the first few bytes and match against the ZIP file signature\u001b[39;00m\n\u001b[32m    432\u001b[39m local_header_magic_number = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPK\u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m read_bytes = f.read(\u001b[38;5;28mlen\u001b[39m(local_header_magic_number))\n\u001b[32m    434\u001b[39m f.seek(start)\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m read_bytes == local_header_magic_number\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_dir = '/data/archive/sd-v1-4'\n",
    "models = ['dpm_solver++', 'uni_pc_bh2', 'dpm_solver_v3', 'rbf_order2', 'rbf_order3']\n",
    "steps = [5, 6, 8, 10, 12, 15, 20]\n",
    "scales= [1.5]\n",
    "\n",
    "for scale in scales:\n",
    "    ref_dir = os.path.join(root_dir, f'dpm_solver++_steps200_scale{scale}')\n",
    "    for step in steps:\n",
    "        for model in models:\n",
    "            comp_dir = os.path.join(root_dir, f'{model}_steps{step}_scale{scale}')\n",
    "            if not os.path.exists(comp_dir):\n",
    "                continue\n",
    "                \n",
    "            mse_list = []\n",
    "            for i in range(2000):\n",
    "                ref_file = os.path.join(ref_dir, f\"{i}.pt\")\n",
    "                comp_file = os.path.join(comp_dir, f\"{i}.pt\")\n",
    "                if not os.path.exists(ref_file) or not os.path.exists(comp_file):\n",
    "                    continue\n",
    "                ref_data = torch.load(ref_file)\n",
    "                comp_data = torch.load(comp_file)\n",
    "                mses = torch.sqrt(torch.mean((ref_data['image'] - comp_data['image']) ** 2, dim=[1, 2, 3]))\n",
    "                mse_list.append(mses)\n",
    "            mses = torch.cat(mse_list, dim=0)\n",
    "            print(comp_dir, f\"{torch.mean(mses).item():.4f}\", f'N={len(mses)}')\n",
    "        print(\"\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
