{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "N = 128\n",
    "M = 128\n",
    "K = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dir = \"/data/edm/scale/rbf_ecp_marginal_M=128\"\n",
    "os.makedirs(scale_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3, 32, 32) (16, 3, 32, 32)\n",
      "(16, 3, 32, 32) (16, 3, 32, 32)\n",
      "(16, 3, 32, 32) (16, 3, 32, 32)\n",
      "(16, 3, 32, 32) (16, 3, 32, 32)\n",
      "(16, 3, 32, 32) (16, 3, 32, 32)\n",
      "(16, 3, 32, 32) (16, 3, 32, 32)\n",
      "(16, 3, 32, 32) (16, 3, 32, 32)\n",
      "(16, 3, 32, 32) (16, 3, 32, 32)\n",
      "torch.Size([128, 3, 32, 32]) torch.Size([128, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'samples/edm-cifar10-32x32-uncond-vp/dpm_solver++_200'\n",
    "noises = []\n",
    "samples = []\n",
    "for i in range(8):\n",
    "    file = os.path.join(root_dir, f'samples_{i}.npz')\n",
    "    data = np.load(file)\n",
    "    print(data['noises'].shape, data['samples'].shape)\n",
    "    noises.append(data['noises'])\n",
    "    samples.append(data['samples'])\n",
    "\n",
    "noises = torch.tensor(np.concatenate(noises, axis=0))[:N]\n",
    "samples = torch.tensor(np.concatenate(samples, axis=0))[:N]\n",
    "print(noises.shape, samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network from \"/data/checkpoints/edm-cifar10-32x32-uncond-vp.pkl\"...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<samplers.utils.NoiseScheduleEDM at 0x76e890754390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from samplers.utils import NoiseScheduleEDM, model_wrapper\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Fix the seed for z = sde.prior_sampling(shape).to(device) in deterministic sampling\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# Load network.\n",
    "ckp_path=\"/data/checkpoints/edm-cifar10-32x32-uncond-vp.pkl\"\n",
    "print(f'Loading network from \"{ckp_path}\"...')\n",
    "with open(ckp_path, \"rb\") as f:\n",
    "    net = pickle.load(f)[\"ema\"].to(device)\n",
    "\n",
    "ns = NoiseScheduleEDM()\n",
    "ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from samplers.rbf_ecp_marginal import RBFSolverECPMarginal\n",
    "sigma_min=0.002\n",
    "sigma_max=80\n",
    "\n",
    "rbf = RBFSolverECPMarginal(ns, algorithm_type=\"data_prediction\", scale_dir=scale_dir)\n",
    "def rbf_sampler(model_fn, z, x, steps, order, skip_type='logSNR'):\n",
    "    with torch.no_grad():\n",
    "        pred = rbf.sample_by_target_matching(\n",
    "            model_fn,\n",
    "            z,\n",
    "            x,\n",
    "            steps=steps,\n",
    "            t_start=sigma_max,\n",
    "            t_end=sigma_min,\n",
    "            order=order,\n",
    "            skip_type=skip_type,\n",
    "        )\n",
    "        return pred\n",
    "\n",
    "sampling_fn = rbf_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 5, order: 3, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=5,p=3,number=0.npz  saved!\n",
      "tensor(0.0234, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 5, order: 4, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=5,p=4,number=0.npz  saved!\n",
      "tensor(0.0218, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 6, order: 3, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=6,p=3,number=0.npz  saved!\n",
      "tensor(0.0174, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 6, order: 4, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=6,p=4,number=0.npz  saved!\n",
      "tensor(0.0169, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 8, order: 3, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=8,p=3,number=0.npz  saved!\n",
      "tensor(0.0103, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 8, order: 4, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=8,p=4,number=0.npz  saved!\n",
      "tensor(0.0215, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 10, order: 3, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=10,p=3,number=0.npz  saved!\n",
      "tensor(0.0046, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 10, order: 4, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=10,p=4,number=0.npz  saved!\n",
      "tensor(0.0065, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 12, order: 3, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=12,p=3,number=0.npz  saved!\n",
      "tensor(0.0037, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 12, order: 4, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=12,p=4,number=0.npz  saved!\n",
      "tensor(0.0041, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 15, order: 3, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=15,p=3,number=0.npz  saved!\n",
      "tensor(0.0025, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 15, order: 4, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=15,p=4,number=0.npz  saved!\n",
      "tensor(0.0022, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 20, order: 3, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=20,p=3,number=0.npz  saved!\n",
      "tensor(0.0012, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 20, order: 4, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=20,p=4,number=0.npz  saved!\n",
      "tensor(0.0133, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 25, order: 3, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=25,p=3,number=0.npz  saved!\n",
      "tensor(0.0007, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 25, order: 4, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=25,p=4,number=0.npz  saved!\n",
      "tensor(0.0043, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 30, order: 3, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=30,p=3,number=0.npz  saved!\n",
      "tensor(0.0006, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 30, order: 4, skip_type: logSNR, lower_order_final: True\n",
      "/data/edm/scale/rbf_ecp_marginal_M=128/NFE=30,p=4,number=0.npz  saved!\n",
      "tensor(0.0002, device='cuda:0', dtype=torch.float64)\n",
      "def sample_by_target_matching start!!!\n",
      "x.shape: torch.Size([128, 3, 32, 32]), target.shape: torch.Size([128, 3, 32, 32]), steps: 35, order: 3, skip_type: logSNR, lower_order_final: True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m zs = zs.to(torch.float64) * sigma_max\n\u001b[32m     10\u001b[39m noise_pred_fn = model_wrapper(net, ns, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m pred = \u001b[43msampling_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_pred_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(F.mse_loss(pred, xs))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mrbf_sampler\u001b[39m\u001b[34m(model_fn, z, x, steps, order, skip_type)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrbf_sampler\u001b[39m(model_fn, z, x, steps, order, skip_type=\u001b[33m'\u001b[39m\u001b[33mlogSNR\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         pred = \u001b[43mrbf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_by_target_matching\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[43mt_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43msigma_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[43mt_end\u001b[49m\u001b[43m=\u001b[49m\u001b[43msigma_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m            \u001b[49m\u001b[43mskip_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scpark/dpm-solver-v32/codebases/edm/samplers/rbf_ecp_marginal.py:359\u001b[39m, in \u001b[36mRBFSolverECPMarginal.sample_by_target_matching\u001b[39m\u001b[34m(self, model_fn, x, target, steps, t_start, t_end, order, skip_type, method, lower_order_final, denoise_to_zero, number)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pindex, log_scale_p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(log_scales):\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m cindex, log_scale_c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(log_scales):\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_loss_by_target_matching\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_scale_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_scale_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambdas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_prev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         loss_grid[pindex, cindex] = loss.item()\n\u001b[32m    361\u001b[39m min_index = np.unravel_index(np.argmin(loss_grid), loss_grid.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scpark/dpm-solver-v32/codebases/edm/samplers/rbf_ecp_marginal.py:293\u001b[39m, in \u001b[36mRBFSolverECPMarginal.get_loss_by_target_matching\u001b[39m\u001b[34m(self, i, x, target, hist, noise_rates, log_scale_p, log_scale_c, lambdas, p, p_prev)\u001b[39m\n\u001b[32m    291\u001b[39m beta = \u001b[32m1\u001b[39m / (np.exp(log_scale_c) * \u001b[38;5;28mabs\u001b[39m(lambdas[i] - lambdas[i-\u001b[32m1\u001b[39m]))\n\u001b[32m    292\u001b[39m lambda_array = torch.flip(lambdas[(i-\u001b[32m1\u001b[39m)-p_prev+\u001b[32m1\u001b[39m:(i-\u001b[32m1\u001b[39m)+\u001b[32m2\u001b[39m], dims=[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m coeffs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_coefficients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambdas\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambdas\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m datas = hist[(i-\u001b[32m1\u001b[39m)-p_prev+\u001b[32m1\u001b[39m:(i-\u001b[32m1\u001b[39m)+\u001b[32m2\u001b[39m][::-\u001b[32m1\u001b[39m]\n\u001b[32m    295\u001b[39m corr = \u001b[38;5;28msum\u001b[39m([coeff * data \u001b[38;5;28;01mfor\u001b[39;00m coeff, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(coeffs, datas)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scpark/dpm-solver-v32/codebases/edm/samplers/rbf_ecp_marginal.py:179\u001b[39m, in \u001b[36mRBFSolverECPMarginal.get_coefficients\u001b[39m\u001b[34m(self, lambda_s, lambda_t, lambdas, beta)\u001b[39m\n\u001b[32m    177\u001b[39m p = \u001b[38;5;28mlen\u001b[39m(lambdas)\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# (p,)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m integral1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_integral_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambda_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambdas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m#print('integral1 :', lambda_s, beta, integral1)\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# (1,)\u001b[39;00m\n\u001b[32m    182\u001b[39m integral2 = \u001b[38;5;28mself\u001b[39m.get_integral_vector(lambda_s, lambda_t, lambdas[:\u001b[32m1\u001b[39m], beta=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scpark/dpm-solver-v32/codebases/edm/samplers/rbf_ecp_marginal.py:130\u001b[39m, in \u001b[36mRBFSolverECPMarginal.get_integral_vector\u001b[39m\u001b[34m(self, lambda_s, lambda_t, lambdas, beta)\u001b[39m\n\u001b[32m    128\u001b[39m     upper = (r_u + s**\u001b[32m2\u001b[39m*h/\u001b[32m2\u001b[39m)/s\n\u001b[32m    129\u001b[39m     lower = (r_u + s**\u001b[32m2\u001b[39m*h/\u001b[32m2\u001b[39m - \u001b[32m1\u001b[39m)/s\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     result = torch.exp(log_prefactor + \u001b[43mlog_erf_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.float()\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# Gaussian-Legendre Quadrature 10-points\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# Coefficients from from sympy.integrals.quadrature import gauss_legendre\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:    \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scpark/dpm-solver-v32/codebases/edm/samplers/rbf_ecp_marginal.py:124\u001b[39m, in \u001b[36mRBFSolverECPMarginal.get_integral_vector.<locals>.log_erf_diff\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_erf_diff\u001b[39m(a, b):\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.log(torch.erfc(b)) + torch.log(\u001b[32m1.0\u001b[39m-\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43merfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43merfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "for steps in [5, 6, 8, 10, 12, 15, 20, 25, 30, 35, 40]:\n",
    "    for order in [3, 4,]:\n",
    "        for _ in range(K):\n",
    "            indexes = np.random.randint(0, len(noises), size=(M,))\n",
    "            zs = noises[indexes].to(device)\n",
    "            xs = samples[indexes].to(device)\n",
    "            zs = zs.to(torch.float64) * sigma_max\n",
    "            noise_pred_fn = model_wrapper(net, ns, None)\n",
    "            pred = sampling_fn(noise_pred_fn, zs, xs, steps, order)\n",
    "            print(F.mse_loss(pred, xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
